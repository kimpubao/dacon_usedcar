{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 8,\n",
    "    'EPOCHS': 50,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa47bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_test=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        self.samples = []\n",
    "        if is_test:\n",
    "            for fname in sorted(os.listdir(root_dir)):\n",
    "                if fname.lower().endswith('.jpg'):\n",
    "                    img_path = os.path.join(root_dir, fname)\n",
    "                    self.samples.append((img_path,))\n",
    "        else:\n",
    "            self.classes = sorted(os.listdir(root_dir))\n",
    "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "            for cls_name in self.classes:\n",
    "                cls_folder = os.path.join(root_dir, cls_name)\n",
    "                for fname in os.listdir(cls_folder):\n",
    "                    if fname.lower().endswith('.jpg'):\n",
    "                        img_path = os.path.join(cls_folder, fname)\n",
    "                        label = self.class_to_idx[cls_name]\n",
    "                        self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_test:\n",
    "            img_path = self.samples[idx][0]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        else:\n",
    "            img_path, label = self.samples[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d9e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "gray_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.449], std=[0.226])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138f87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './train'\n",
    "test_root = './test'\n",
    "\n",
    "full_dataset = CustomImageDataset(train_root, transform=None)\n",
    "targets = [label for _, label in full_dataset.samples]\n",
    "class_names = full_dataset.classes\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset_rgb = Subset(CustomImageDataset(train_root, transform=rgb_transform), train_idx)\n",
    "val_dataset_rgb = Subset(CustomImageDataset(train_root, transform=rgb_transform), val_idx)\n",
    "train_dataset_gray = Subset(CustomImageDataset(train_root, transform=gray_transform), train_idx)\n",
    "val_dataset_gray = Subset(CustomImageDataset(train_root, transform=gray_transform), val_idx)\n",
    "\n",
    "train_loader_rgb = DataLoader(train_dataset_rgb, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader_rgb = DataLoader(val_dataset_rgb, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "train_loader_gray = DataLoader(train_dataset_gray, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader_gray = DataLoader(val_dataset_gray, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e767c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_first_conv(model, model_type):\n",
    "    if model_type == 'densenet':\n",
    "        conv = model.features.conv0\n",
    "        new_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight = nn.Parameter(conv.weight.sum(dim=1, keepdim=True))\n",
    "        model.features.conv0 = new_conv\n",
    "    elif model_type == 'vgg':\n",
    "        conv = model.features[0]\n",
    "        new_conv = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight = nn.Parameter(conv.weight.sum(dim=1, keepdim=True))\n",
    "        model.features[0] = new_conv\n",
    "    elif model_type == 'efficientnet':\n",
    "        conv = model._conv_stem\n",
    "        new_conv = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        with torch.no_grad():\n",
    "            new_conv.weight = nn.Parameter(conv.weight.sum(dim=1, keepdim=True))\n",
    "        model._conv_stem = new_conv\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119a9eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\old_car\\car_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes, is_gray=False):\n",
    "        super().__init__()\n",
    "        in_chans = 1 if is_gray else 3\n",
    "\n",
    "        # timm 모델 로딩 (분류기 제거)\n",
    "        self.densenet = timm.create_model('densenet121', pretrained=True, num_classes=0, in_chans=in_chans)\n",
    "        self.vgg = timm.create_model('vgg16_bn', pretrained=True, num_classes=0, in_chans=in_chans)\n",
    "        self.effnet = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0, in_chans=in_chans)\n",
    "\n",
    "        # 각 모델 출력 차원 (미리 확인된 값)\n",
    "        self.dim1 = 1024  # densenet121\n",
    "        self.dim2 = 4096  # vgg16_bn\n",
    "        self.dim3 = 1280  # efficientnet_b0\n",
    "\n",
    "        # 최종 classifier\n",
    "        self.classifier = nn.Linear(self.dim1 + self.dim2 + self.dim3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.densenet(x)\n",
    "        x2 = self.vgg(x)\n",
    "        x3 = self.effnet(x)\n",
    "        x_cat = torch.cat((x1, x2, x3), dim=1)\n",
    "        return self.classifier(x_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bf8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStateEnsemble(nn.Module):\n",
    "    def __init__(self, num_classes, gray_weight=0.6, rgb_weight=0.4):\n",
    "        super().__init__()\n",
    "        self.rgb_ensemble = EnsembleModel(num_classes, is_gray=False)\n",
    "        self.gray_ensemble = EnsembleModel(num_classes, is_gray=True)\n",
    "        total = gray_weight + rgb_weight\n",
    "        self.gray_weight = gray_weight / total\n",
    "        self.rgb_weight = rgb_weight / total\n",
    "\n",
    "    def forward(self, rgb_x, gray_x):\n",
    "        rgb_logits = self.rgb_ensemble(rgb_x)\n",
    "        gray_logits = self.gray_ensemble(gray_x)\n",
    "        rgb_probs = F.softmax(rgb_logits, dim=1)\n",
    "        gray_probs = F.softmax(gray_logits, dim=1)\n",
    "        final_probs = self.rgb_weight * rgb_probs + self.gray_weight * gray_probs\n",
    "        return final_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8727a132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 5.9560\n",
      "Epoch 2 Train Loss: 5.8201\n",
      "Epoch 3 Train Loss: 5.7197\n",
      "Epoch 4 Train Loss: 5.6774\n",
      "Epoch 5 Train Loss: 5.6557\n",
      "Epoch 6 Train Loss: 5.6445\n",
      "Epoch 7 Train Loss: 5.6361\n",
      "Epoch 8 Train Loss: 5.6282\n",
      "Epoch 9 Train Loss: 5.6238\n",
      "Epoch 10 Train Loss: 5.6187\n",
      "Epoch 11 Train Loss: 5.6145\n",
      "Epoch 12 Train Loss: 5.6115\n",
      "Epoch 13 Train Loss: 5.6083\n",
      "Epoch 14 Train Loss: 5.6050\n",
      "Epoch 15 Train Loss: 5.6031\n",
      "Epoch 16 Train Loss: 5.6032\n",
      "Epoch 17 Train Loss: 5.6021\n",
      "Epoch 18 Train Loss: 5.6016\n",
      "Epoch 19 Train Loss: 5.6012\n",
      "Epoch 20 Train Loss: 5.6002\n",
      "Epoch 21 Train Loss: 5.5992\n",
      "Epoch 22 Train Loss: 5.5987\n",
      "Epoch 23 Train Loss: 5.5978\n",
      "Epoch 24 Train Loss: 5.5967\n",
      "Epoch 25 Train Loss: 5.5961\n",
      "Epoch 26 Train Loss: 5.5962\n",
      "Epoch 27 Train Loss: 5.5953\n",
      "Epoch 28 Train Loss: 5.5956\n",
      "Epoch 29 Train Loss: 5.5944\n",
      "Epoch 30 Train Loss: 5.5937\n",
      "Epoch 31 Train Loss: 5.5932\n",
      "Epoch 32 Train Loss: 5.5924\n",
      "Epoch 33 Train Loss: 5.5925\n",
      "Epoch 34 Train Loss: 5.5923\n",
      "Epoch 35 Train Loss: 5.5924\n",
      "Epoch 36 Train Loss: 5.5919\n",
      "Epoch 37 Train Loss: 5.5923\n",
      "Epoch 38 Train Loss: 5.5914\n",
      "Epoch 39 Train Loss: 5.5908\n",
      "Epoch 40 Train Loss: 5.5906\n",
      "Epoch 41 Train Loss: 5.5908\n",
      "Epoch 42 Train Loss: 5.5907\n",
      "Epoch 43 Train Loss: 5.5908\n",
      "Epoch 44 Train Loss: 5.5901\n",
      "Epoch 45 Train Loss: 5.5903\n",
      "Epoch 46 Train Loss: 5.5904\n",
      "Epoch 47 Train Loss: 5.5901\n",
      "Epoch 48 Train Loss: 5.5901\n",
      "Epoch 49 Train Loss: 5.5901\n",
      "Epoch 50 Train Loss: 5.5898\n"
     ]
    }
   ],
   "source": [
    "model = MultiStateEnsemble(num_classes=len(class_names)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for (rgb_imgs, labels), (gray_imgs, _) in zip(train_loader_rgb, train_loader_gray):\n",
    "        rgb_imgs, gray_imgs, labels = rgb_imgs.to(device), gray_imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(rgb_imgs, gray_imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Train Loss: {train_loss/len(train_loader_rgb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c956b",
   "metadata": {},
   "source": [
    "#### 추론 부분 아직은 돌리지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "200d38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_rgb = CustomImageDataset(test_root, transform=rgb_transform, is_test=True)\n",
    "test_dataset_gray = CustomImageDataset(test_root, transform=gray_transform, is_test=True)\n",
    "test_loader_rgb = DataLoader(test_dataset_rgb, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "test_loader_gray = DataLoader(test_dataset_gray, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for rgb_imgs, gray_imgs in zip(test_loader_rgb, test_loader_gray):\n",
    "        rgb_imgs, gray_imgs = rgb_imgs.to(device), gray_imgs.to(device)\n",
    "        probs = model(rgb_imgs, gray_imgs)\n",
    "        for prob in probs.cpu():\n",
    "            result = {class_names[i]: prob[i].item() for i in range(len(class_names))}\n",
    "            results.append(result)\n",
    "pred = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16c11e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv', encoding='utf-8')\n",
    "class_columns = submission.columns[1:]\n",
    "pred = pred[class_columns]\n",
    "submission[class_columns] = pred.values\n",
    "submission.to_csv('ensemble_submission.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
