{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'BATCH_SIZE': 64,\n",
    "    'EPOCHS': 100,\n",
    "    'LEARNING_RATE': 1e-4,\n",
    "    'SEED': 42,\n",
    "    'NUM_CLASSES': 397,\n",
    "    'RGB_WEIGHT': 0.4,\n",
    "    'GRAY_WEIGHT': 0.6\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels=None, transform=None, mode='rgb', is_test=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"L\" if self.mode == 'gray' else \"RGB\")\n",
    "        if self.mode == 'gray':\n",
    "            image = image.convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.is_test:\n",
    "            return image, os.path.basename(img_path)\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "transform_rgb = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_gray = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root = './train'\n",
    "test_root = './test'\n",
    "\n",
    "class_names = sorted(os.listdir(train_root))\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "\n",
    "image_paths, labels = [], []\n",
    "for cls_name in class_names:\n",
    "    for fname in os.listdir(os.path.join(train_root, cls_name)):\n",
    "        if fname.lower().endswith('.jpg'):\n",
    "            image_paths.append(os.path.join(train_root, cls_name, fname))\n",
    "            labels.append(class_to_idx[cls_name])\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, stratify=labels, random_state=CFG['SEED']\n",
    ")\n",
    "\n",
    "train_loader_rgb = DataLoader(CustomImageDataset(train_paths, train_labels, transform_rgb, 'rgb'), batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader_rgb   = DataLoader(CustomImageDataset(val_paths, val_labels, transform_rgb, 'rgb'), batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "train_loader_gray = DataLoader(CustomImageDataset(train_paths, train_labels, transform_gray, 'gray'), batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader_gray   = DataLoader(CustomImageDataset(val_paths, val_labels, transform_gray, 'gray'), batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "test_image_paths = sorted([os.path.join(test_root, f) for f in os.listdir(test_root) if f.endswith('.jpg')])\n",
    "test_filenames = [os.path.basename(p) for p in test_image_paths]\n",
    "\n",
    "test_loader_rgb = DataLoader(CustomImageDataset(test_image_paths, transform=transform_rgb, mode='rgb', is_test=True), batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "test_loader_gray = DataLoader(CustomImageDataset(test_image_paths, transform=transform_gray, mode='gray', is_test=True), batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "sample_submission = pd.read_csv('./sample_submission.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 및 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.convnext_base(pretrained=True)\n",
    "    model.classifier[2] = nn.Linear(model.classifier[2].in_features, CFG['NUM_CLASSES'])\n",
    "    return model.to(device)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "def train_model(model, train_loader, val_loader, model_path):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                val_loss += criterion(model(x), y).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}\")\n",
    "        if val_loss < stopper.best_loss:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"Best model saved:\", model_path)\n",
    "        stopper(val_loss)\n",
    "        if stopper.early_stop:\n",
    "            print(\"Early stopping.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 및 저장 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device)\n",
    "            probs = F.softmax(model(x), dim=1).cpu().numpy()\n",
    "            result.append(probs)\n",
    "    return np.concatenate(result, axis=0)\n",
    "\n",
    "# RGB + Gray 모델 추론 병합용 함수\n",
    "# 학습은 RGB/Gray 따로 하고, 추론 단계에서 softmax 결과를 병합하는 구조\n",
    "# Gray 60%, RGB 40% 비율로 가중치 적용\n",
    "def ensemble_predict(rgb_probs, gray_probs, w_rgb=0.4, w_gray=0.6):\n",
    "    probs = w_rgb * rgb_probs + w_gray * gray_probs\n",
    "    return probs\n",
    "\n",
    "# 추론 후 저장 함수\n",
    "# sample_submission 포맷을 기준으로 예측 확률을 저장합니다.\n",
    "def save_submission_probs(filenames, probs, sample_df):\n",
    "    df = pd.DataFrame(probs, columns=sample_df.columns[1:])\n",
    "    df.insert(0, \"ID\", filenames)\n",
    "    df = df[sample_df.columns]\n",
    "    df.to_csv(\"baseline_submission_gray.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행 셀 (학습 + 추론 + 제출 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB 학습\n",
    "model_rgb = get_model()\n",
    "train_model(model_rgb, train_loader_rgb, val_loader_rgb, \"best_model_rgb.pth\")\n",
    "\n",
    "# GRAY 학습\n",
    "model_gray = get_model()\n",
    "train_model(model_gray, train_loader_gray, val_loader_gray, \"best_model_gray.pth\")\n",
    "\n",
    "# 최종 추론 및 앙상블 실행\n",
    "model_rgb.load_state_dict(torch.load(\"best_model_rgb.pth\"))\n",
    "model_gray.load_state_dict(torch.load(\"best_model_gray.pth\"))\n",
    "\n",
    "rgb_pred = predict(model_rgb, test_loader_rgb)\n",
    "gray_pred = predict(model_gray, test_loader_gray)\n",
    "\n",
    "# Gray 60%, RGB 40% 비율로 softmax 확률을 앙상블\n",
    "final_pred = ensemble_predict(rgb_pred, gray_pred, w_rgb=0.4, w_gray=0.6)\n",
    "\n",
    "save_submission_probs(test_filenames, final_pred, sample_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
